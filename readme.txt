Decision Tree

这是一个基于信息熵的决策树实现。
选用ID3算法。
样本数据一共包含26个数据集。最终要分类的属性class，有good和bad两个值，其中good有18个样本，bad有8个样本，为计算每个属性的信息增益，首先计算class分类所需要的期望信息.
I(18,8)=-18/26log(18/26)-8/26log(8/26)=0.891
接下来计算每个属性的熵，然后选取具有最高信息增益的属性作为测试属性。
以age属性为例：
对于age<=30，有9个good ,2个bad: I(9,2)= -9/11log(9/11)-2/11log(2/11)=0.684
对于age31-51，有8个good,4个bad: I(8,4)= -8/12log(8/12)-4/12log(4/12)=0.918
对于age>50，有1个good,2个bad: I(1,2)= -1/3log(1/3)-2/3log(2/3)=0.918
因此，如果样本按age划分，对于以给定样本分类对应的熵为：
11/26*0.684+12/26*0.918+3/26*0.918=0.819
这种划分的信息增益为：
G(age)=0.891-0.819=0.072
算出所有属性的信息增益后选取具有最高信息增益的属性作为测试属性。然后循环进行，直至决策树生成。
